{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c156cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>.dataframe td { white-space: nowrap; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "sns.set_theme()\n",
    "\n",
    "# jupyter notebook full-width display\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "# no text wrapping\n",
    "display(HTML(\"<style>.dataframe td { white-space: nowrap; }</style>\"))\n",
    "\n",
    "# pandas formatting\n",
    "pd.set_option('display.float_format', '{:.3f}'.format)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 600)\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1797adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base dataframes\n",
    "df_hist = pd.read_pickle('calculations\\df_hist.pickle')\n",
    "df_spec = pd.read_pickle('calculations\\df_spec.pickle')\n",
    "df_arch = pd.read_pickle('calculations\\df_arch.pickle')\n",
    "df_prob = pd.read_pickle('calculations\\df_prob.pickle')\n",
    "df_matching_stats = pd.read_pickle('calculations\\df_matching_stats.pickle')\n",
    "df_summary = pd.read_pickle('calculations\\df_summary.pickle')\n",
    "\n",
    "# drop error calc from last notebook - improve in this notebook\n",
    "df_summary = df_summary.drop(['length_MSE', 'length_ME'], axis=1, level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f3e1d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import saved lists\n",
    "with open('calculations\\\\exact_counts_match.pickle', 'rb') as f:\n",
    "    exact_counts_match = pickle.load(f)\n",
    "with open('calculations\\\\strong_sample_matches_tolerance_0.pickle', 'rb') as f:\n",
    "    strong_sample_matches_tolerance_0 = pickle.load(f)\n",
    "with open('calculations\\\\strong_sample_matches_tolerance_1.pickle', 'rb') as f:\n",
    "    strong_sample_matches_tolerance_0 = pickle.load(f)\n",
    "with open('calculations\\\\strong_sample_matches_tolerance_2.pickle', 'rb') as f:\n",
    "    strong_sample_matches_tolerance_0 = pickle.load(f)\n",
    "with open('calculations\\\\potential_fish_matches_tolerance_0.pickle', 'rb') as f:\n",
    "    potential_fish_matches_tolerance_0 = pickle.load(f)\n",
    "with open('calculations\\\\potential_fish_matches_tolerance_1.pickle', 'rb') as f:\n",
    "    potential_fish_matches_tolerance_1 = pickle.load(f)\n",
    "with open('calculations\\\\potential_fish_matches_tolerance_2.pickle', 'rb') as f:\n",
    "    potential_fish_matches_tolerance_2 = pickle.load(f)\n",
    "with open('calculations\\\\bad_sample_matches_tolerance_0.pickle', 'rb') as f:\n",
    "    bad_sample_matches_tolerance_0 = pickle.load(f)\n",
    "with open('calculations\\\\bad_sample_matches_tolerance_1.pickle', 'rb') as f:\n",
    "    bad_sample_matches_tolerance_1 = pickle.load(f)\n",
    "with open('calculations\\\\bad_sample_matches_tolerance_2.pickle', 'rb') as f:\n",
    "    bad_sample_matches_tolerance_2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730814ac",
   "metadata": {},
   "source": [
    "# NOT DOUBLE COUNTED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "943fe550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4390,\n",
       " 4391,\n",
       " 4392,\n",
       " 4393,\n",
       " 4394,\n",
       " 4395,\n",
       " 4396,\n",
       " 4397,\n",
       " 4398,\n",
       " 4399,\n",
       " 4400,\n",
       " 4408,\n",
       " 4599,\n",
       " 5133,\n",
       " 5319,\n",
       " 7877,\n",
       " 7880,\n",
       " 7884]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no specimen data == not double counted\n",
    "[x for x in df_hist.sample_id.unique() if x not in df_summary.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "86cee9f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>n_matches</th>\n",
       "      <th>n_hist</th>\n",
       "      <th>n_spec</th>\n",
       "      <th>matches_proportion</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5246</th>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>0.136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5266</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "      <td>0.071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5270</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>0.050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5271</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5348</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>0.091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5357</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>0.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7532</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "      <td>0.059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7857</th>\n",
       "      <td>27</td>\n",
       "      <td>51</td>\n",
       "      <td>32</td>\n",
       "      <td>0.529</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          n_matches n_hist n_spec matches_proportion\n",
       "                                                    \n",
       "sample_id                                           \n",
       "5246              3     22      7              0.136\n",
       "5266              1     14      2              0.071\n",
       "5270              1     20      3              0.050\n",
       "5271              3     30      5              0.100\n",
       "5348              1     11     10              0.091\n",
       "5357              2     20      2              0.100\n",
       "7532              1     17      6              0.059\n",
       "7857             27     51     32              0.529"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# more bio data than spec data == at least some bio samples aren't double counted\n",
    "df_summary[df_summary.n_hist > df_summary.n_spec].iloc[:, 26:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d4ddd4",
   "metadata": {},
   "source": [
    "# improved bins, plotting and error checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ab244db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    38505\n",
       "8    34192\n",
       "0      242\n",
       "9      231\n",
       "4      228\n",
       "2      225\n",
       "5      224\n",
       "1      207\n",
       "7      206\n",
       "6      187\n",
       "Name: fork_length, dtype: Int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bins used by specimen table\n",
    "# looks like bio data doesn't need to end with a 3 or 8\n",
    "(df_spec.fork_length % 10).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "376fea4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                      74666\n",
       "fork_length             74447\n",
       "weight                    429\n",
       "river_age               74664\n",
       "notes                   74666\n",
       "sample_id               74666\n",
       "sex_id                      6\n",
       "status_id               74666\n",
       "age_type                74664\n",
       "sweep_id                74666\n",
       "life_stage_id           74666\n",
       "old_id                  74666\n",
       "smart_river_age         74664\n",
       "smart_river_age_type    74664\n",
       "matching_id             74666\n",
       "dtype: int64"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_spec.notna().sum()\n",
    "# note: there are only 6 sex data and they are the import error (should be bio) from the other notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "413773fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "weight   0.841\n",
       "sex_id   0.000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check: confirm that values ending in not 3/8 have more weight/sex\n",
    "\n",
    "# still no sex data, but most of the weight data is here \n",
    "# (you would expect exactly 80% if it was 100% because more detailed measurements could include n%5==3)\n",
    "\n",
    "df_spec[df_spec.fork_length % 5 != 3][['weight', 'sex_id']].notna().sum() / df_spec[['weight', 'sex_id']].notna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "484de704",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   74447.000\n",
       "mean       57.040\n",
       "std        23.221\n",
       "min        23.000\n",
       "25%        43.000\n",
       "50%        48.000\n",
       "75%        68.000\n",
       "max       163.000\n",
       "Name: fork_length, dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bins go from 23 to 163\n",
    "df_spec.fork_length.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcea924",
   "metadata": {},
   "source": [
    "# improved fork length plotting function\n",
    "using bins as utilised by specimen table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b572ab97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fork_length_by_sample(df_specimen, df_historical, sample_id, feature='fork_length', bin_width=5, density=False, subtitle=''):\n",
    "    \n",
    "    figsize=(16,4)\n",
    "    bins_plot = [x*5 + 20 for x in range(30)]  # centered on n%5==3 like df_spec, rounded to int%5 (could use +20.5 also)\n",
    "        \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.xlim(20, 170)  # use same scale for all histograms for easy comparison\n",
    "    df_specimen.loc[df_specimen.sample_id==sample_id, feature].dropna().hist(alpha=0.5, color=sns.color_palette()[0], density=density, label=f'Specimen {feature}', bins=bins_plot)\n",
    "    df_historical.loc[df_historical.sample_id==sample_id, feature].dropna().hist(alpha=0.5, color=sns.color_palette()[1], density=density, label=f'Bioligical {feature}', bins=bins_plot)\n",
    "    \n",
    "    feature_title = feature.title().replace(\"_\",\" \")\n",
    "    plt.legend(loc='upper right')\n",
    "    subtitle = ' - ' + subtitle if subtitle else ''\n",
    "    plt.title(f'Sample {sample_id}: {feature_title} Comparison - Specimen vs Biological Data{subtitle}')\n",
    "    plt.ylabel('Counts')\n",
    "    plt.xlabel(f'{feature_title}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25583ae9",
   "metadata": {},
   "source": [
    "# improved error calculating\n",
    "using bins as utilised by the specimen table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "d7c7050d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "weight_tolerance = 1\n",
    "potential_fish_matches = []  # list(sample, spec, hist, hist_total) - these should only trigger if an exact match on sex/len/wt within tolerance, if exists\n",
    "strong_sample_matches = list()  # a match is found for every fish in df_hist - sample likely contains duplicated spec/bio\n",
    "bad_sample_matches = set()  # df_hist contains unmatchable fish - some fish are definitely not duplicated spec/bio\n",
    "last_sample = 0\n",
    "df = pd.DataFrame()\n",
    "hist_total, hist_matches = 999, 0 \n",
    "\n",
    "for i, row in df_hist.sort_values(['sample_id', 'id']).iterrows():\n",
    "\n",
    "    fish_id, sample_id, fork_length, weight, sex_id = row[['id', 'sample_id', 'fork_length', 'weight', 'sex_id']]\n",
    "    current_bin = fork_length - fork_length%5, fork_length - fork_length%5 + 5  # these are int bins n%5, could add 0.5 per above note\n",
    "    \n",
    "    if last_sample != sample_id:\n",
    "        df = df_spec[df_spec.sample_id==sample_id]\n",
    "        # strong matches\n",
    "        if hist_matches == hist_total:\n",
    "            strong_sample_matches += [last_sample]\n",
    "        hist_matches = 0\n",
    "        hist_total = df_hist[df_hist.sample_id==sample_id].shape[0]\n",
    "        \n",
    "    if not df.empty:\n",
    "        \n",
    "        results = df[\n",
    "            ((df.fork_length>=current_bin[0]) & (df.fork_length<current_bin[1])) # check if fork_length is in the same bin\n",
    "            & (\n",
    "                ((df.weight>=weight-weight_tolerance) & (df.weight>=weight-weight_tolerance))\n",
    "                | df.weight.isnull()\n",
    "            )\n",
    "            & ((df.sex_id==sex_id) | df.sex_id.isnull())\n",
    "        ]\n",
    "        if not results.empty:\n",
    "            hist_matches += 1\n",
    "            potential_fish_matches += [[sample_id, fish_id, results.iloc[0].id, hist_total, hist_matches, fork_length, results.iloc[[0]].fork_length.values[0]]]\n",
    "            df = df.drop(results.iloc[[0]].index[0]) # drop this row so it doesn't get matched again\n",
    "        else:\n",
    "            bad_sample_matches.add(sample_id)  # triggers if results is empty (there are no matches)\n",
    "\n",
    "    else:\n",
    "        bad_sample_matches.add(sample_id)  # triggers if df is empty\n",
    "\n",
    "    last_sample = sample_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "ed8e6edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matches</th>\n",
       "      <th>total</th>\n",
       "      <th>sample_SSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4485</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4578</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7639</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7691</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7644</th>\n",
       "      <td>138</td>\n",
       "      <td>174</td>\n",
       "      <td>4251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7653</th>\n",
       "      <td>231</td>\n",
       "      <td>266</td>\n",
       "      <td>4485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7637</th>\n",
       "      <td>225</td>\n",
       "      <td>270</td>\n",
       "      <td>5472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7635</th>\n",
       "      <td>223</td>\n",
       "      <td>275</td>\n",
       "      <td>6095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7591</th>\n",
       "      <td>290</td>\n",
       "      <td>346</td>\n",
       "      <td>6865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           matches  total  sample_SSE\n",
       "sample_id                            \n",
       "7611             1      1           0\n",
       "4485             1      1           0\n",
       "4578             5      5           0\n",
       "7639             1      1           1\n",
       "7691             1      1           1\n",
       "...            ...    ...         ...\n",
       "7644           138    174        4251\n",
       "7653           231    266        4485\n",
       "7637           225    270        5472\n",
       "7635           223    275        6095\n",
       "7591           290    346        6865\n",
       "\n",
       "[768 rows x 3 columns]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use potential fish matches to calculate error\n",
    "error_penalty_per_unmatched_fish = 100  # arbitrary\n",
    "\n",
    "df_matches = pd.DataFrame(potential_fish_matches, columns=['sample_id', 'hist_id', 'spec_id', 'total_hist', 'cumulative_matches', 'hist_fork_length', 'spec_fork_length'])\n",
    "df_match_counts = df_matches.groupby('sample_id').max()[['cumulative_matches', 'total_hist']].rename({'total_hist':'total', 'cumulative_matches':'matches'}, axis=1)\n",
    "\n",
    "df_matches = pd.merge(\n",
    "    df_matches,\n",
    "    df_match_counts,\n",
    "    on='sample_id',\n",
    "    how='left'\n",
    ").drop(['cumulative_matches', 'total_hist'], axis=1)\n",
    "\n",
    "df_matches['fish_sq_error'] = (df_matches['hist_fork_length'] - df_matches['spec_fork_length']) ** 2\n",
    "df_matches['unmatched_penalty'] = (df_matches['total'] - df_matches['matches']) * error_penalty_per_unmatched_fish\n",
    "df_matches = df_matches.merge(\n",
    "    pd.DataFrame(df_matches[['sample_id', 'fish_sq_error', 'unmatched_penalty']].groupby('sample_id').agg({'fish_sq_error':'sum', 'unmatched_penalty':'max'}).sum(axis=1), columns=['sample_SSE']),\n",
    "    on='sample_id',\n",
    "    how='left'\n",
    ").drop(['fish_sq_error', 'unmatched_penalty'], axis=1)\n",
    "\n",
    "df_matches.groupby('sample_id').max()[['matches', 'total', 'sample_SSE']].sort_values('sample_SSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "8cbaa8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 59.8 s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>matches</th>\n",
       "      <th>total</th>\n",
       "      <th>sample_SSE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4578</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4485</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4635</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4634</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7622</th>\n",
       "      <td>238</td>\n",
       "      <td>271</td>\n",
       "      <td>4071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7653</th>\n",
       "      <td>231</td>\n",
       "      <td>266</td>\n",
       "      <td>4241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7637</th>\n",
       "      <td>225</td>\n",
       "      <td>270</td>\n",
       "      <td>5136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7635</th>\n",
       "      <td>223</td>\n",
       "      <td>275</td>\n",
       "      <td>5851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7591</th>\n",
       "      <td>290</td>\n",
       "      <td>346</td>\n",
       "      <td>6548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>768 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           matches  total  sample_SSE\n",
       "sample_id                            \n",
       "4578             5      5           0\n",
       "7611             1      1           0\n",
       "4485             1      1           0\n",
       "4635             2      2           1\n",
       "4634             1      1           1\n",
       "...            ...    ...         ...\n",
       "7622           238    271        4071\n",
       "7653           231    266        4241\n",
       "7637           225    270        5136\n",
       "7635           223    275        5851\n",
       "7591           290    346        6548\n",
       "\n",
       "[768 rows x 3 columns]"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# if we sort descending, do we get the same number of strong and impossible matches?\n",
    "\n",
    "weight_tolerance = 1\n",
    "potential_fish_matches = []  # list(sample, spec, hist, hist_total) - these should only trigger if an exact match on sex/len/wt within tolerance, if exists\n",
    "strong_sample_matches = list()  # a match is found for every fish in df_hist - sample likely contains duplicated spec/bio\n",
    "bad_sample_matches = set()  # df_hist contains unmatchable fish - some fish are definitely not duplicated spec/bio\n",
    "last_sample = 0\n",
    "df = pd.DataFrame()\n",
    "hist_total, hist_matches = 999, 0 \n",
    "\n",
    "for i, row in df_hist.sort_values(['sample_id', 'id'], ascending=False).iterrows():\n",
    "\n",
    "    fish_id, sample_id, fork_length, weight, sex_id = row[['id', 'sample_id', 'fork_length', 'weight', 'sex_id']]\n",
    "    current_bin = fork_length - fork_length%5, fork_length - fork_length%5 + 5  # these are int bins n%5, could add 0.5 per above note\n",
    "    \n",
    "    if last_sample != sample_id:\n",
    "        df = df_spec[df_spec.sample_id==sample_id]\n",
    "        # strong matches\n",
    "        if hist_matches == hist_total:\n",
    "            strong_sample_matches += [last_sample]\n",
    "        hist_matches = 0\n",
    "        hist_total = df_hist[df_hist.sample_id==sample_id].shape[0]\n",
    "        \n",
    "    if not df.empty:\n",
    "        \n",
    "        results = df[\n",
    "            ((df.fork_length>=current_bin[0]) & (df.fork_length<current_bin[1])) # check if fork_length is in the same bin\n",
    "            & (\n",
    "                ((df.weight>=weight-weight_tolerance) & (df.weight>=weight-weight_tolerance))\n",
    "                | df.weight.isnull()\n",
    "            )\n",
    "            & ((df.sex_id==sex_id) | df.sex_id.isnull())\n",
    "        ]\n",
    "        if not results.empty:\n",
    "            hist_matches += 1\n",
    "            potential_fish_matches += [[sample_id, fish_id, results.iloc[0].id, hist_total, hist_matches, fork_length, results.iloc[[0]].fork_length.values[0]]]\n",
    "            df = df.drop(results.iloc[[0]].index[0]) # drop this row so it doesn't get matched again\n",
    "        else:\n",
    "            bad_sample_matches.add(sample_id)  # triggers if results is empty (there are no matches)\n",
    "\n",
    "    else:\n",
    "        bad_sample_matches.add(sample_id)  # triggers if df is empty\n",
    "\n",
    "    last_sample = sample_id\n",
    "    \n",
    "    \n",
    "# use potential fish matches to calculate error\n",
    "error_penalty_per_unmatched_fish = 100  # arbitrary\n",
    "\n",
    "df_matches_desc = pd.DataFrame(potential_fish_matches, columns=['sample_id', 'hist_id', 'spec_id', 'total_hist', 'cumulative_matches', 'hist_fork_length', 'spec_fork_length'])\n",
    "df_match_counts = df_matches_desc.groupby('sample_id').max()[['cumulative_matches', 'total_hist']].rename({'total_hist':'total', 'cumulative_matches':'matches'}, axis=1)\n",
    "\n",
    "df_matches_desc = pd.merge(\n",
    "    df_matches_desc,\n",
    "    df_match_counts,\n",
    "    on='sample_id',\n",
    "    how='left'\n",
    ").drop(['cumulative_matches', 'total_hist'], axis=1)\n",
    "\n",
    "df_matches_desc['fish_sq_error'] = (df_matches_desc['hist_fork_length'] - df_matches_desc['spec_fork_length']) ** 2\n",
    "df_matches_desc['unmatched_penalty'] = (df_matches_desc['total'] - df_matches_desc['matches']) * error_penalty_per_unmatched_fish\n",
    "df_matches_desc = df_matches_desc.merge(\n",
    "    pd.DataFrame(df_matches_desc[['sample_id', 'fish_sq_error', 'unmatched_penalty']].groupby('sample_id').agg({'fish_sq_error':'sum', 'unmatched_penalty':'max'}).sum(axis=1), columns=['sample_SSE']),\n",
    "    on='sample_id',\n",
    "    how='left'\n",
    ").drop(['fish_sq_error', 'unmatched_penalty'], axis=1)\n",
    "\n",
    "df_matches_desc.groupby('sample_id').max()[['matches', 'total', 'sample_SSE']].sort_values('sample_SSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fac8485",
   "metadata": {},
   "source": [
    "            matches\ttotal\tsample_SSE\n",
    "    sample_id\t\t\t\n",
    "    7611\t1\t1\t0\n",
    "    4485\t1\t1\t0\n",
    "    4578\t5\t5\t0\n",
    "    7639\t1\t1\t1\n",
    "    7691\t1\t1\t1\n",
    "    ...\t...\t...\t...\n",
    "    7644\t138\t174\t4251\n",
    "    7653\t231\t266\t4485\n",
    "    7637\t225\t270\t5472\n",
    "    7635\t223\t275\t6095\n",
    "    7591\t290\t346\t6865"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "779773c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sample_id</th>\n",
       "      <th>SSE_asc</th>\n",
       "      <th>SSE_desc</th>\n",
       "      <th>delta</th>\n",
       "      <th>delta_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000</td>\n",
       "      <td>768.000</td>\n",
       "      <td>768.000</td>\n",
       "      <td>768.000</td>\n",
       "      <td>768.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6406.895</td>\n",
       "      <td>535.060</td>\n",
       "      <td>527.673</td>\n",
       "      <td>7.387</td>\n",
       "      <td>0.061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1345.255</td>\n",
       "      <td>773.377</td>\n",
       "      <td>738.046</td>\n",
       "      <td>67.110</td>\n",
       "      <td>0.200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4404.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>-614.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7169.500</td>\n",
       "      <td>274.000</td>\n",
       "      <td>302.500</td>\n",
       "      <td>4.000</td>\n",
       "      <td>0.016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95%</th>\n",
       "      <td>7862.650</td>\n",
       "      <td>1879.300</td>\n",
       "      <td>1789.700</td>\n",
       "      <td>81.000</td>\n",
       "      <td>0.190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97.5%</th>\n",
       "      <td>7928.825</td>\n",
       "      <td>2988.475</td>\n",
       "      <td>2824.775</td>\n",
       "      <td>122.775</td>\n",
       "      <td>0.769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99.5%</th>\n",
       "      <td>7990.165</td>\n",
       "      <td>4289.610</td>\n",
       "      <td>4099.050</td>\n",
       "      <td>232.310</td>\n",
       "      <td>1.429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>8001.000</td>\n",
       "      <td>6865.000</td>\n",
       "      <td>6548.000</td>\n",
       "      <td>336.000</td>\n",
       "      <td>1.646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sample_id  SSE_asc  SSE_desc    delta  delta_scaled\n",
       "count    768.000  768.000   768.000  768.000       768.000\n",
       "mean    6406.895  535.060   527.673    7.387         0.061\n",
       "std     1345.255  773.377   738.046   67.110         0.200\n",
       "min     4404.000    0.000     0.000 -614.000         0.000\n",
       "50%     7169.500  274.000   302.500    4.000         0.016\n",
       "95%     7862.650 1879.300  1789.700   81.000         0.190\n",
       "97.5%   7928.825 2988.475  2824.775  122.775         0.769\n",
       "99.5%   7990.165 4289.610  4099.050  232.310         1.429\n",
       "max     8001.000 6865.000  6548.000  336.000         1.646"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SSE_comparison = pd.merge(\n",
    "    df_matches.groupby('sample_id').max()['sample_SSE'].reset_index().rename({'sample_SSE':'SSE_asc'}, axis=1),\n",
    "    df_matches_desc.groupby('sample_id').max()['sample_SSE'].reset_index().rename({'sample_SSE':'SSE_desc'}, axis=1),\n",
    "    on='sample_id'\n",
    ")\n",
    "SSE_comparison['delta'] = SSE_comparison['SSE_asc'] - SSE_comparison['SSE_desc']\n",
    "SSE_comparison['delta_scaled'] = (SSE_comparison['delta'] / ((SSE_comparison['SSE_asc'] + SSE_comparison['SSE_desc']) / 2)).abs().fillna(0)\n",
    "SSE_comparison.sort_values('delta_scaled', ascending=False).head(22)\n",
    "SSE_comparison.describe(percentiles=[0.95, 0.975,0.995])\n",
    "\n",
    "# these look different enough that we should run both and take the best match"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
